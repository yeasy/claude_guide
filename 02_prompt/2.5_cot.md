## 2.5 链式思维与逐步推理

人类在回答“23 乘以 14 是多少”时，不会凭空蹦出“322”，而是会在很多张纸上列竖式计算。
同样，让 Claude 直接回答复杂的逻辑问题，它可能会“凭直觉”猜一个答案（然后猜错）。

**Chain of Thought (CoT)** 是一种让模型“列竖式”的技术。通过强制模型将思考过程显性化，可以极大地提高其在数学、逻辑推理和代码生成任务上的准确率。

### 2.5.1 为什么模型需要“思考时间”？

大语言模型本质上是**概率预测机**。它是逐个 Token 生成的，就像你在打字时输入法联想下一个词一样。
如果没有 CoT，模型必须在生成第一个 Token 时就决定最终答案。这对于简单的知识检索（“中国首都在哪”）没问题，但对于需要多步推理的问题（“我应该怎么设计这个系统架构”），这就像要求在一秒钟内不仅算出结果，还要直接写在试卷上。

CoT 给了模型一个**缓冲区**，让它生成更多的 Token 来进行中间计算（Intermediate Computation），从而“推导出”正确答案。

### 2.5.2 激发 CoT 的两种模式

#### 零样本思维链 (Zero-Shot CoT)
这是最简单粗暴的方法。
只需在 Prompt 结尾加一句咒语：

> **"Let's think step by step." (让我们一步步思考。)**

这句神奇的话能瞬间激活模型的推理模式。
*   **User**: "我有3个苹果，吃了2个，又买了5个，分给朋友1个，还剩几个？"
*   **Prompt**: "Let's think step by step."
*   **Claude**: "1. 初始: 3。 2. 吃了2个: 3-2=1。 3. 买了5个: 1+5=6。 4. 分给朋友1个: 6-1=5。 答案是 5。"

#### 结构化思维链 (Structured CoT via XML)
在企业级应用中，需要更受控的 CoT。不希望用户看到那一长串思考过程，只希望看到最终结果。
这时，可以利用 XML 标签将“思考”和“回答”分开。

**System Prompt:**
```xml
<instruction>
在回答任何问题之前，你必须先在 <thinking> 标签中进行详细的步骤推理。
然后，在 <answer> 标签中给出最终结论。
不要在 <answer> 标签之外输出任何针对用户的回复。
</instruction>
```

**User:**
"分析一下 A 公司收购 B 公司的风险。"

**Claude:**
```xml
<thinking>
1. 市场垄断风险：两家公司份额合计超过 60%...
2. 财务风险：A 公司现金流并不充裕...
3. 文化冲突：A 是狼性文化，B 是养老文化...
</thinking>
<answer>
主要风险有三点：反垄断审查、现金流压力以及企业文化融合困难。
</answer>
```

在后端处理时，可以利用正则表达式提取 `<answer>` 里的内容展示给用户，而将 `<thinking>` 里的内容作为日志保存，用于后续的 Prompt 调试。

### 2.5.3 CoT 的进阶技巧

#### Plan-and-Solve (先计划，后执行)
对于特别复杂的任务（如写代码），仅仅“一步步思考”可能还不够，容易走偏。
可以让 Claude 先写**大纲**。

**Prompt:**
```text
请帮我用 Python 写一个贪吃蛇游戏。
在写代码之前，请先在 <plan> 标签中列出你的设计思路，包括类结构、主要函数和核心算法。
```

**Claude:**
```xml
<plan>
1. 类设计: Snake, Food, GameBoard...
2. 移动逻辑: 坐标更新，头部添加，尾部移除...
3. 碰撞检测: 撞墙，撞自己...
</plan>
```
这种方法显著减少了代码逻辑错误。

#### Self-Correction (自我修正)
让模型在得出结论前，先自己检查一遍。

**Prompt:**
```text
...在 <thinking> 中推理完毕后，请在 <reflection> 标签中反思你的推理是否有漏洞。如果有，请修正。最后输出 <answer>。
```

### 2.5.4 什么时候不需要 CoT？

CoT 不是免费的。它会消耗更多的 Token，增加延迟。
以下场景**不推荐**使用 CoT：
1.  **创意写作**：写诗、写故事。（逻辑太严密反而没灵气）
2.  **简单问答**：“今天几月几号？”（无需推理）
3.  **大量简单数据提取**：从 1000 份简历提取姓名。（直接提取即可，不用思考）

### 2.5.5 Claude 的 Extended Thinking (扩展思考模式)

*(注：截至 2025 年，先进模型如 Claude 4 Opus/Sonnet 和 Claude 3.5 Sonnet 内置了更强的隐式推理能力)*

在最新的 Claude 原生功能中，可以通过参数 `extended_thinking=True` (假设 API 支持)，让模型在后台进行从**数秒到数分钟**的深度思考，然后再输出结果。这适用于数学证明、科研难题攻关等极端场景。

---

现在，Claude 已经学会了如何思考。但作为开发者，还需要它不仅想得对，还要**输出得漂亮**。如何让它乖乖吐出 JSON 而不是废话？

➡️ [输出格式控制 (Output Formatting)](2.6_format.md)
